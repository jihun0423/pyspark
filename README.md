# pyspark

이전 프로젝트때 데이터 크기가 큰 데이터셋으로 정제 및 분석을 해본 적이 있었는데, 전처리할 때도 시간이 생각보다 소요됐고, 특히 머신러닝 모델을 통하여 학습할때 시간이 매우 걸려서 다양한 시도를 하지 못했었다.
