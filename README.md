# pyspark

이전 프로젝트때 데이터 크기가 큰 데이터셋으로 정제 및 분석을 해본 적이 있었는데, 전처리할 때도 시간이 생각보다 소요됐고, 특히 머신러닝 모델을 통하여 학습할때 시간이 매우 걸려서 다양한 시도를 하지 못했었다.  
이때 이 문제를 해결하고자 방법을 찾던 중, spark를 이용하여 분산처리를 하면 속도가 향상된다는 것을 알게 되었지만, 그때 당시는 학습할 시간이 없어 설치만 해두었었다.  
앞으로 다양한 데이터들을 접하게 될텐데, 그 때를 대비하고자 pyspark를 학습하기로 하였다.


강의에서는 Databricks를 사용하여 실습을 하였지만, databricks는 무료 버전의 경우 들어갈 때마다 클러스터를 생성하여 실행해 주어야 하기 때문에, 시간이 걸려서 로컬에 pyspark를 설치하여 사용하기로 하였고, 성공적으로 설치하였다.  
